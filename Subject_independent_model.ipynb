{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Shift the Overt labels to be zero-indexed\n",
    "overt_labels_shifted = overt_labels - 11  # Subtract the minimum label (11)\n",
    "\n",
    "# Shift the Covert labels to be zero-indexed\n",
    "covert_labels_shifted = covert_labels - 21  # Subtract the minimum label (21)\n",
    "\n",
    "# Now convert to categorical\n",
    "overt_labels_categorical = to_categorical(overt_labels_shifted, num_classes=5)\n",
    "covert_labels_categorical = to_categorical(covert_labels_shifted, num_classes=5)\n",
    "\n",
    "# Train-test split for Overt data\n",
    "X_overt_train, X_overt_test, y_overt_train, y_overt_test = train_test_split(overt_data, overt_labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split for Covert data\n",
    "X_covert_train, X_covert_test, y_covert_train, y_covert_test = train_test_split(covert_data, covert_labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transpose the input data so that it matches the expected shape\n",
    "X_overt_train = X_overt_train.transpose((0, 2, 1))  # Shape becomes (batch_size, time_steps, features)\n",
    "X_overt_test = X_overt_test.transpose((0, 2, 1))  # Same for test data\n",
    "X_covert_train = X_covert_train.transpose((0, 2, 1))  # Shape becomes (batch_size, time_steps, features)\n",
    "X_covert_test = X_covert_test.transpose((0, 2, 1))  # Same for test data\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 5:  # Warm-up phase: increase the learning rate gradually\n",
    "        return lr * (epoch + 1) / 5\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        return lr * 0.9  # Reduce by 10% every 5 epochs\n",
    "    return lr\n",
    "# Define the Bi-LSTM model architecture with L2 regularization\n",
    "def create_bi_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Bidirectional LSTM Layer with L2 regularization\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01)), input_shape=input_shape))  # L2 regularization\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Second Bidirectional LSTM Layer with L2 regularization\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False, kernel_regularizer=l2(0.01))))  # L2 regularization\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Fully connected layer with L2 regularization\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "\n",
    "    # Output layer with softmax activation for 5 classes\n",
    "    model.add(Dense(5, activation='softmax'))  # 5 classes\n",
    "\n",
    "    # Compile the model with RMSProp optimizer\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Model for Overt Data\n",
    "model_overt = create_bi_lstm_model((1000, 128))\n",
    "model_overt.summary()\n",
    "\n",
    "# Train the Bi-LSTM model for Overt Data with learning rate scheduler\n",
    "history_overt = model_overt.fit(X_overt_train, y_overt_train, epochs=10, batch_size=32, validation_data=(X_overt_test, y_overt_test), callbacks=[LearningRateScheduler(lr_scheduler)])\n",
    "\n",
    "# Evaluate the model on Overt data\n",
    "test_loss_overt, test_accuracy_overt = model_overt.evaluate(X_overt_test, y_overt_test)\n",
    "print(f\"Overt Test Accuracy: {test_accuracy_overt * 100:.2f}%\")\n",
    "\n",
    "# Model for Covert Data\n",
    "model_covert = create_bi_lstm_model((1000, 128))\n",
    "model_covert.summary()\n",
    "\n",
    "# Train the Bi-LSTM model for Covert Data with learning rate scheduler\n",
    "history_covert = model_covert.fit(X_covert_train, y_covert_train, epochs=10, batch_size=32, validation_data=(X_covert_test, y_covert_test), callbacks=[LearningRateScheduler(lr_scheduler)])\n",
    "\n",
    "# Evaluate the model on Covert data\n",
    "test_loss_covert, test_accuracy_covert = model_covert.evaluate(X_covert_test, y_covert_test)\n",
    "print(f\"Covert Test Accuracy: {test_accuracy_covert * 100:.2f}%\")\n",
    "\n",
    "# Plot training and validation accuracy for Overt Data and Covert Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for Overt Data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_overt.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_overt.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Overt Bi-LSTM Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for Covert Data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_covert.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_covert.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Covert Bi-LSTM Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
